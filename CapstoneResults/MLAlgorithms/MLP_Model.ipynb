{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for converting series data to a supervised data of format, t-1, t, t+1\n",
    "## Basically feeding in the (t-1)th data to predict the t data\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time_since_last_recording   latency      cost  reliability  \\\n",
      "0                   0.000000  0.015102  0.193359            1   \n",
      "1                   0.016458  0.015117  0.310547            1   \n",
      "2                   0.003947  0.015297  0.169922            1   \n",
      "3                   0.013916  0.014803  0.191406            1   \n",
      "4                   0.016191  0.014817  0.167969            1   \n",
      "\n",
      "   time_since_last_ping  ping_time  \n",
      "0                   0.0   0.000000  \n",
      "1                   0.0   0.000000  \n",
      "2                   0.0   0.000000  \n",
      "3                   0.0   0.000000  \n",
      "4                   0.0   0.491071  \n"
     ]
    }
   ],
   "source": [
    " \n",
    "# load dataset\n",
    "dataset = read_csv('/Users/sakshikarnawat/Desktop/valet-tool/parse_tactics/normalized_tva_server_1_tactic_1_train.csv')\n",
    "dataset= dataset.drop(columns=[\"timestamp\",\"ping_timestamp\",\"ping_success\"])\n",
    "values = dataset.values\n",
    "print(dataset.head(5))\n",
    "## Load Validation\n",
    "validation = read_csv('/Users/sakshikarnawat/Desktop/valet-tool/parse_tactics/normalized_tva_server_1_tactic_1_test.csv')\n",
    "validation= validation.drop(columns=[\"timestamp\",\"ping_timestamp\",\"ping_success\"])\n",
    "values_validation = validation.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)   var2(t)  \\\n",
      "1        0.0   0.015102   0.193359        1.0        0.0        0.0  0.015117   \n",
      "\n",
      "    var3(t)  var4(t)  \n",
      "1  0.310547      1.0  \n"
     ]
    }
   ],
   "source": [
    "## Calling the function to do the preprocessing the data and removing unwanted columns\n",
    "\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(values, 1, 1)\n",
    "reframed_validation = series_to_supervised(values_validation, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[6,10,11]], axis=1, inplace=True)\n",
    "reframed_validation.drop(reframed_validation.columns[[6,7,8]], axis=1, inplace=True)\n",
    "print(reframed.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12156, 1, 6) (12156, 3) (2604, 1, 6) (2604, 3)\n"
     ]
    }
   ],
   "source": [
    "## Splitting the data into training and validation sets\n",
    "\n",
    "\n",
    "train = reframed.values\n",
    "test = reframed_validation.values\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-3], train[:,-3:]\n",
    "test_X, test_y = test[:, :-3], test[:,-3:]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12156/12156 [==============================] - 1s 103us/step - loss: 0.0231\n",
      "Epoch 2/20\n",
      "12156/12156 [==============================] - 1s 77us/step - loss: 8.6049e-05\n",
      "Epoch 3/20\n",
      "12156/12156 [==============================] - 1s 70us/step - loss: 7.4210e-05: 0s - loss: 7.342\n",
      "Epoch 4/20\n",
      "12156/12156 [==============================] - 1s 42us/step - loss: 7.2401e-05\n",
      "Epoch 5/20\n",
      "12156/12156 [==============================] - 0s 34us/step - loss: 7.0663e-05\n",
      "Epoch 6/20\n",
      "12156/12156 [==============================] - 1s 43us/step - loss: 6.9901e-05: 0s - loss: \n",
      "Epoch 7/20\n",
      "12156/12156 [==============================] - 1s 44us/step - loss: 6.9680e-05\n",
      "Epoch 8/20\n",
      "12156/12156 [==============================] - 1s 60us/step - loss: 6.9086e-05\n",
      "Epoch 9/20\n",
      "12156/12156 [==============================] - 0s 39us/step - loss: 6.8652e-05\n",
      "Epoch 10/20\n",
      "12156/12156 [==============================] - 1s 42us/step - loss: 6.8614e-05\n",
      "Epoch 11/20\n",
      "12156/12156 [==============================] - 0s 35us/step - loss: 6.8529e-05\n",
      "Epoch 12/20\n",
      "12156/12156 [==============================] - 1s 55us/step - loss: 6.8670e-05: 0s - loss: 6.8\n",
      "Epoch 13/20\n",
      "12156/12156 [==============================] - 0s 38us/step - loss: 6.9509e-05\n",
      "Epoch 14/20\n",
      "12156/12156 [==============================] - 1s 44us/step - loss: 7.0120e-05\n",
      "Epoch 15/20\n",
      "12156/12156 [==============================] - 0s 37us/step - loss: 6.7014e-05\n",
      "Epoch 16/20\n",
      "12156/12156 [==============================] - 1s 49us/step - loss: 6.9017e-05\n",
      "Epoch 17/20\n",
      "12156/12156 [==============================] - 1s 66us/step - loss: 6.8841e-05\n",
      "Epoch 18/20\n",
      "12156/12156 [==============================] - 1s 42us/step - loss: 6.8212e-05\n",
      "Epoch 19/20\n",
      "12156/12156 [==============================] - 1s 42us/step - loss: 6.8465e-05\n",
      "Epoch 20/20\n",
      "12156/12156 [==============================] - 0s 34us/step - loss: 6.8100e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Run this cell for MLP , else Run the next cell for LSTM\n",
    "\n",
    "# flatten input\n",
    "n_input = train_X.shape[1] * train_X.shape[2]\n",
    "X = train_X.reshape((train_X.shape[0], n_input))\n",
    "\n",
    "# define MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_dim=n_input))\n",
    "model.add(Dense(3))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history= model.fit(X, train_y, epochs=20, verbose=1)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Doing the same process for testing dataset\n",
    "\n",
    "test_dataset = read_csv('/Users/sakshikarnawat/Desktop/valet-tool/parse_tactics/normalized_tva_server_1_tactic_1_validation.csv')\n",
    "test_dataset= test_dataset.drop(columns=[\"timestamp\",\"ping_timestamp\",\"ping_success\"])\n",
    "test_values = test_dataset.values\n",
    "reframed_test = series_to_supervised(test_values, 1, 1)\n",
    "reframed_test.drop(reframed_test.columns[[6,10,11]], axis=1, inplace=True)\n",
    "testset = reframed_test.values\n",
    "testset_X, testset_y = testset[:, :-3], testset[:,-3:]\n",
    "testdataReshaped = testset_X.reshape((testset_X.shape[0], 1, testset_X.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01667418 0.17202792 0.99934816]\n",
      " [0.01651097 0.17308882 0.9993767 ]\n",
      " [0.01659112 0.17247385 0.9993565 ]\n",
      " ...\n",
      " [0.01629247 0.17568257 0.9996975 ]\n",
      " [0.01642333 0.1720694  1.0001742 ]\n",
      " [0.01645025 0.17083171 1.0001988 ]]\n"
     ]
    }
   ],
   "source": [
    "## Feeding the test dataset for predictions\n",
    "import pandas as pd\n",
    "\n",
    "## For MLP use below line only\n",
    "yhat = model.predict(testset_X)\n",
    "\n",
    "print(yhat)\n",
    "dataset = pd.DataFrame({'predicted_Latency': yhat[:, 0], 'predicted_Cost': yhat[:, 1],\n",
    "                       'predicted_Reliability': yhat[:, 2]})\n",
    "dataset['predicted_Reliability'].loc[dataset['predicted_Reliability'] >0.5] = 1\n",
    "dataset['predicted_Reliability'].loc[dataset['predicted_Reliability'] <0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [test_dataset, dataset]\n",
    "result = pd.concat(frames,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_since_last_recording</th>\n",
       "      <th>latency</th>\n",
       "      <th>cost</th>\n",
       "      <th>reliability</th>\n",
       "      <th>time_since_last_ping</th>\n",
       "      <th>ping_time</th>\n",
       "      <th>predicted_Latency</th>\n",
       "      <th>predicted_Cost</th>\n",
       "      <th>predicted_Reliability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010972</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.094776</td>\n",
       "      <td>0.016674</td>\n",
       "      <td>0.172028</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>0.094776</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.173089</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.095119</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>0.172474</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.094886</td>\n",
       "      <td>0.016630</td>\n",
       "      <td>0.173693</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015571</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.094886</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>0.174308</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.015474</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.094592</td>\n",
       "      <td>0.016665</td>\n",
       "      <td>0.173952</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.016747</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.094447</td>\n",
       "      <td>0.016607</td>\n",
       "      <td>0.174892</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007560</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>0.162109</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.094667</td>\n",
       "      <td>0.016636</td>\n",
       "      <td>0.172090</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.095725</td>\n",
       "      <td>0.016592</td>\n",
       "      <td>0.172343</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.016296</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.095725</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.173258</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_since_last_recording   latency      cost  reliability  \\\n",
       "0                   0.010972  0.017155  0.160156            1   \n",
       "1                   0.004683  0.014948  0.167969            1   \n",
       "2                   0.000736  0.015292  0.164062            1   \n",
       "3                   0.007895  0.016283  0.169922            1   \n",
       "4                   0.000000  0.015571  0.173828            1   \n",
       "5                   0.011440  0.015474  0.171875            1   \n",
       "6                   0.005954  0.016747  0.175781            1   \n",
       "7                   0.007560  0.015070  0.162109            1   \n",
       "8                   0.001673  0.014855  0.164062            1   \n",
       "9                   0.003546  0.016296  0.167969            1   \n",
       "\n",
       "   time_since_last_ping  ping_time  predicted_Latency  predicted_Cost  \\\n",
       "0              0.006864   0.094776           0.016674        0.172028   \n",
       "1              0.011622   0.094776           0.016511        0.173089   \n",
       "2              0.000272   0.095119           0.016591        0.172474   \n",
       "3              0.003058   0.094886           0.016630        0.173693   \n",
       "4              0.003058   0.094886           0.016522        0.174308   \n",
       "5              0.001699   0.094592           0.016665        0.173952   \n",
       "6              0.001223   0.094447           0.016607        0.174892   \n",
       "7              0.003874   0.094667           0.016636        0.172090   \n",
       "8              0.001087   0.095725           0.016592        0.172343   \n",
       "9              0.004757   0.095725           0.016578        0.173258   \n",
       "\n",
       "   predicted_Reliability  \n",
       "0                    1.0  \n",
       "1                    1.0  \n",
       "2                    1.0  \n",
       "3                    1.0  \n",
       "4                    1.0  \n",
       "5                    1.0  \n",
       "6                    1.0  \n",
       "7                    1.0  \n",
       "8                    1.0  \n",
       "9                    1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "result.head(10)\n",
    "# result.to_csv('/Users/manali/Desktop/PingPredictions/predictions_MLP_server_3_tactic_1_Normalized.csv', sep=',', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0149483  0.16796875 1.        ]\n",
      " [0.01529248 0.1640625  1.        ]\n",
      " [0.0162831  0.16992187 1.        ]\n",
      " ...\n",
      " [0.01635488 0.1796875  1.        ]\n",
      " [0.01666088 0.17382812 1.        ]\n",
      " [0.01505033 0.16601562 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(testset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  0.04450584864832884\n"
     ]
    }
   ],
   "source": [
    "## Finding the root mean squared error of the model\n",
    "\n",
    "rmse = sqrt(mean_squared_error(yhat, testset_y))\n",
    "print('Test RMSE: ' , rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  0.0019807705639079544\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(yhat, testset_y)\n",
    "print('Test MSE: ',  mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:  0.0068792368619197955\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(yhat, testset_y)\n",
    "print('Test MAE: ',  mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
