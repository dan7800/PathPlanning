{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for converting series data to a supervised data of format, t-1, t, t+1\n",
    "## Basically feeding in the (t-1)th data to predict the t data\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time_since_last_recording   latency      cost  reliability  \\\n",
      "0                   0.000000  0.015102  0.193359            1   \n",
      "1                   0.016458  0.015117  0.310547            1   \n",
      "2                   0.003947  0.015297  0.169922            1   \n",
      "3                   0.013916  0.014803  0.191406            1   \n",
      "4                   0.016191  0.014817  0.167969            1   \n",
      "\n",
      "   time_since_last_ping  ping_time  \n",
      "0                   0.0   0.000000  \n",
      "1                   0.0   0.000000  \n",
      "2                   0.0   0.000000  \n",
      "3                   0.0   0.000000  \n",
      "4                   0.0   0.491071  \n"
     ]
    }
   ],
   "source": [
    "#/Users/sakshikarnawat/Desktop/valet-tool\n",
    "# load dataset\n",
    "dataset = read_csv('/Users/sakshikarnawat/Desktop/CapstoneResults/normalized_tva_server_1_tactic_1_train.csv')\n",
    "dataset= dataset.drop(columns=[\"timestamp\",\"ping_timestamp\",\"ping_success\"])\n",
    "values = dataset.values\n",
    "print(dataset.head(5))\n",
    "## Load Validation\n",
    "validation = read_csv('/Users/sakshikarnawat/Desktop/valet-tool/parse_tactics/normalized_tva_server_1_tactic_1_test.csv')\n",
    "validation= validation.drop(columns=[\"timestamp\",\"ping_timestamp\",\"ping_success\"])\n",
    "values_validation = validation.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)   var2(t)  \\\n",
      "1        0.0   0.015102   0.193359        1.0        0.0        0.0  0.015117   \n",
      "\n",
      "    var3(t)  var4(t)  \n",
      "1  0.310547      1.0  \n"
     ]
    }
   ],
   "source": [
    "## Calling the function to do the preprocessing the data and removing unwanted columns\n",
    "\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(values, 1, 1)\n",
    "reframed_validation = series_to_supervised(values_validation, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[6,10,11]], axis=1, inplace=True)\n",
    "reframed_validation.drop(reframed_validation.columns[[6,10,11]], axis=1, inplace=True)\n",
    "print(reframed.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12156, 1, 6) (12156, 3) (2604, 1, 6) (2604, 3)\n"
     ]
    }
   ],
   "source": [
    "## Splitting the data into training and validation sets\n",
    "\n",
    "\n",
    "train = reframed.values\n",
    "test = reframed_validation.values\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-3], train[:,-3:]\n",
    "test_X, test_y = test[:, :-3], test[:,-3:]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1000)              4028000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3003      \n",
      "=================================================================\n",
      "Total params: 4,031,003\n",
      "Trainable params: 4,031,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 12156 samples, validate on 2604 samples\n",
      "Epoch 1/20\n",
      "12156/12156 [==============================] - 17s 1ms/step - loss: 0.0222 - val_loss: 3.0294e-04\n",
      "Epoch 2/20\n",
      "12156/12156 [==============================] - 17s 1ms/step - loss: 1.0952e-04 - val_loss: 1.3749e-04\n",
      "Epoch 3/20\n",
      "12156/12156 [==============================] - 16s 1ms/step - loss: 7.7541e-05 - val_loss: 1.1368e-04\n",
      "Epoch 4/20\n",
      "12156/12156 [==============================] - 17s 1ms/step - loss: 7.6708e-05 - val_loss: 1.0176e-04\n",
      "Epoch 5/20\n",
      "12156/12156 [==============================] - 17s 1ms/step - loss: 7.6493e-05 - val_loss: 9.2667e-05\n",
      "Epoch 6/20\n",
      "12156/12156 [==============================] - 17s 1ms/step - loss: 7.6225e-05 - val_loss: 8.8672e-05\n",
      "Epoch 7/20\n",
      "12156/12156 [==============================] - 18s 1ms/step - loss: 7.5821e-05 - val_loss: 9.2599e-05\n",
      "Epoch 8/20\n",
      "12156/12156 [==============================] - 17s 1ms/step - loss: 7.5395e-05 - val_loss: 9.8724e-05\n",
      "Epoch 9/20\n",
      "12156/12156 [==============================] - 17s 1ms/step - loss: 7.4961e-05 - val_loss: 1.0277e-04\n",
      "Epoch 10/20\n",
      "12156/12156 [==============================] - 17s 1ms/step - loss: 7.4545e-05 - val_loss: 1.0542e-04\n",
      "Epoch 11/20\n",
      "12156/12156 [==============================] - 16s 1ms/step - loss: 7.4222e-05 - val_loss: 1.0773e-04\n",
      "Epoch 12/20\n",
      "12156/12156 [==============================] - 18s 1ms/step - loss: 7.3985e-05 - val_loss: 1.1027e-04\n",
      "Epoch 13/20\n",
      "12156/12156 [==============================] - 18s 1ms/step - loss: 7.3795e-05 - val_loss: 1.1308e-04\n",
      "Epoch 14/20\n",
      "12156/12156 [==============================] - 19s 2ms/step - loss: 7.3595e-05 - val_loss: 1.1628e-04\n",
      "Epoch 15/20\n",
      "12156/12156 [==============================] - 19s 2ms/step - loss: 7.3337e-05 - val_loss: 1.2066e-04\n",
      "Epoch 16/20\n",
      "12156/12156 [==============================] - 19s 2ms/step - loss: 7.3027e-05 - val_loss: 1.2519e-04\n",
      "Epoch 17/20\n",
      "12156/12156 [==============================] - 16s 1ms/step - loss: 7.2725e-05 - val_loss: 1.2723e-04\n",
      "Epoch 18/20\n",
      "12156/12156 [==============================] - 17s 1ms/step - loss: 7.2485e-05 - val_loss: 1.2672e-04\n",
      "Epoch 19/20\n",
      "12156/12156 [==============================] - 17s 1ms/step - loss: 7.2313e-05 - val_loss: 1.2515e-04\n",
      "Epoch 20/20\n",
      "12156/12156 [==============================] - 17s 1ms/step - loss: 7.2190e-05 - val_loss: 1.2300e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design LSTM network  has 1000 hidden layers , used adam optimizer and mse loss function\n",
    "model = Sequential()\n",
    "model.add(LSTM(1000, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(3))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=20, batch_size=72, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time_since_last_recording   latency      cost  reliability  \\\n",
      "0                   0.010972  0.017155  0.160156            1   \n",
      "1                   0.004683  0.014948  0.167969            1   \n",
      "2                   0.000736  0.015292  0.164062            1   \n",
      "3                   0.007895  0.016283  0.169922            1   \n",
      "4                   0.000000  0.015571  0.173828            1   \n",
      "\n",
      "   time_since_last_ping  ping_time  \n",
      "0              0.006864   0.094776  \n",
      "1              0.011622   0.094776  \n",
      "2              0.000272   0.095119  \n",
      "3              0.003058   0.094886  \n",
      "4              0.003058   0.094886  \n",
      "(2605, 6) (2605, 6)\n"
     ]
    }
   ],
   "source": [
    "### Doing the same process for testing dataset\n",
    "\n",
    "#test_dataset = read_csv('normalized_tva_server_2_tactic_1_validation.csv')\n",
    "test_dataset = read_csv('/Users/sakshikarnawat/Desktop/valet-tool/parse_tactics/normalized_tva_server_1_tactic_1_validation.csv')\n",
    "test_dataset= test_dataset.drop(columns=[\"timestamp\",\"ping_timestamp\",\"ping_success\"])\n",
    "print(test_dataset.head())\n",
    "test_values = test_dataset.values\n",
    "reframed_test = series_to_supervised(test_values, 1, 1)\n",
    "reframed_test.drop(reframed_test.columns[[6,10,11]], axis=1, inplace=True)\n",
    "testset = reframed_test.values\n",
    "testset_X, testset_y = testset[:, :-3], testset[:,-3:]\n",
    "testdataReshaped = testset_X.reshape((testset_X.shape[0], 1, testset_X.shape[1]))\n",
    "print(testset_X.shape, testset_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01903555 0.1872092  0.99912703]\n",
      " [0.01904735 0.18772766 0.9994844 ]\n",
      " [0.01886934 0.18781856 0.9990374 ]\n",
      " ...\n",
      " [0.01739606 0.18795678 1.0025557 ]\n",
      " [0.01741081 0.18693472 1.0010298 ]\n",
      " [0.01743751 0.1865083  1.0004317 ]]\n"
     ]
    }
   ],
   "source": [
    "## Feeding the test dataset for predictions\n",
    "import pandas as pd\n",
    "\n",
    "yhat = model.predict(testdataReshaped)\n",
    "\n",
    "print(yhat)\n",
    "dataset = pd.DataFrame({'predicted_Latency': yhat[:, 0], 'predicted_Cost': yhat[:, 1],\n",
    "                       'predicted_Reliability': yhat[:, 2]})\n",
    "dataset['predicted_Reliability'].loc[dataset['predicted_Reliability'] >0.5] = 1\n",
    "dataset['predicted_Reliability'].loc[dataset['predicted_Reliability'] <0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [test_dataset, dataset]\n",
    "result = pd.concat(frames,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_since_last_recording</th>\n",
       "      <th>latency</th>\n",
       "      <th>cost</th>\n",
       "      <th>reliability</th>\n",
       "      <th>time_since_last_ping</th>\n",
       "      <th>ping_time</th>\n",
       "      <th>predicted_Latency</th>\n",
       "      <th>predicted_Cost</th>\n",
       "      <th>predicted_Reliability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010972</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>0.160156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.094776</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>0.187209</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>0.094776</td>\n",
       "      <td>0.019047</td>\n",
       "      <td>0.187728</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.095119</td>\n",
       "      <td>0.018869</td>\n",
       "      <td>0.187819</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>0.169922</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.094886</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.187913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015571</td>\n",
       "      <td>0.173828</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.094886</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.188372</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.015474</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.094592</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>0.187917</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.016747</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.094447</td>\n",
       "      <td>0.018959</td>\n",
       "      <td>0.188359</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007560</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>0.162109</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.094667</td>\n",
       "      <td>0.018986</td>\n",
       "      <td>0.187426</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.095725</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.187762</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.016296</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.095725</td>\n",
       "      <td>0.018948</td>\n",
       "      <td>0.187907</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_since_last_recording   latency      cost  reliability  \\\n",
       "0                   0.010972  0.017155  0.160156            1   \n",
       "1                   0.004683  0.014948  0.167969            1   \n",
       "2                   0.000736  0.015292  0.164062            1   \n",
       "3                   0.007895  0.016283  0.169922            1   \n",
       "4                   0.000000  0.015571  0.173828            1   \n",
       "5                   0.011440  0.015474  0.171875            1   \n",
       "6                   0.005954  0.016747  0.175781            1   \n",
       "7                   0.007560  0.015070  0.162109            1   \n",
       "8                   0.001673  0.014855  0.164062            1   \n",
       "9                   0.003546  0.016296  0.167969            1   \n",
       "\n",
       "   time_since_last_ping  ping_time  predicted_Latency  predicted_Cost  \\\n",
       "0              0.006864   0.094776           0.019036        0.187209   \n",
       "1              0.011622   0.094776           0.019047        0.187728   \n",
       "2              0.000272   0.095119           0.018869        0.187819   \n",
       "3              0.003058   0.094886           0.018989        0.187913   \n",
       "4              0.003058   0.094886           0.018911        0.188372   \n",
       "5              0.001699   0.094592           0.019028        0.187917   \n",
       "6              0.001223   0.094447           0.018959        0.188359   \n",
       "7              0.003874   0.094667           0.018986        0.187426   \n",
       "8              0.001087   0.095725           0.018890        0.187762   \n",
       "9              0.004757   0.095725           0.018948        0.187907   \n",
       "\n",
       "   predicted_Reliability  \n",
       "0                    1.0  \n",
       "1                    1.0  \n",
       "2                    1.0  \n",
       "3                    1.0  \n",
       "4                    1.0  \n",
       "5                    1.0  \n",
       "6                    1.0  \n",
       "7                    1.0  \n",
       "8                    1.0  \n",
       "9                    1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "result.head(10)\n",
    "# result.to_csv('/Users/manali/Desktop/PingPredictions/predictions_LSTM_server3_tactic1_Normalized.csv', sep=',', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0149483  0.16796875 1.        ]\n",
      " [0.01529248 0.1640625  1.        ]\n",
      " [0.0162831  0.16992187 1.        ]\n",
      " ...\n",
      " [0.01635488 0.1796875  1.        ]\n",
      " [0.01666088 0.17382812 1.        ]\n",
      " [0.01505033 0.16601562 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(testset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  0.045975128899720594\n"
     ]
    }
   ],
   "source": [
    "## Finding the root mean squared error of the model\n",
    "import numpy as np\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(yhat, testset_y))\n",
    "print('Test RMSE: ' , rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  0.002113712477345924\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(yhat, testset_y)\n",
    "print('Test MSE: ',  mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:  0.010061197087830676\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(yhat, testset_y)\n",
    "print('Test MAE: ',  mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
